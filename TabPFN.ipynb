{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40351cb1-757b-4221-b7e6-5054b2779bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcefe25f-0b96-4023-914c-da7f3554722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn_ext import TabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c9e103-d226-4250-a87b-d3313769912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated shape: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_repeated = np.repeat(X, 1, axis=0)\n",
    "y_repeated = np.repeat(y, 1, axis=0)\n",
    "\n",
    "print(\"Repeated shape:\", X_repeated.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_repeated, y_repeated, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90da2fc-4711-46d8-b465-3546b93a77eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_repeated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca935d1-5d8b-4e5a-a827-7b1444713433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel_mode=block with return_as=list\n",
      "Reduced from 76 to 37 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 76 to 34 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 76 to 37 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 76 to 33 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 31 to 13 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 31 to 13 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 31 to 13 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Reduced from 31 to 13 features\n",
      "MPS Memory currently allocated (bytes): 0\n",
      "MPS Total allocated memory by driver (bytes): 475136\n",
      "Fitted 8 preprocessors for caching. No preprocessing: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TabPFNClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TabPFNClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a classifier\n",
    "clf = TabPFNClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f2315c-3dd8-4ce7-aa80-8255f8e5c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter_outputs 4\n",
      "parallel_execute: Running inference on ensemble members.\n",
      "parallel_execute: Completed inference on ensemble members.\n",
      "Only one device detected. Executing in the current thread.\n",
      "Reduced from 76 to 37 features\n",
      "Using torch.inference_mode for inference.\n",
      "MPS Memory currently allocated (bytes): before self.model() : 29832192\n",
      "MPS Total allocated memory by driver (bytes): before self.model(): 34045952\n",
      "MPS Memory currently allocated (bytes): before transformer_encoder : 117814784\n",
      "MPS Total allocated memory by driver (bytes): before transformer_encoder: 1264451584\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 642205184\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 1232994304\n",
      "Elapsed time: 0.116949 seconds\n",
      "MPS Memory currently allocated (bytes): finished 729603584\n",
      "MPS Total allocated memory by driver (bytes): finished 1289617408\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 394576384\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 1295925248\n",
      "Elapsed time: 0.130853 seconds\n",
      "MPS Memory currently allocated (bytes): finished 438275584\n",
      "MPS Total allocated memory by driver (bytes): finished 12953993216\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 511107584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 8914862080\n",
      "Elapsed time: 0.077719 seconds\n",
      "MPS Memory currently allocated (bytes): finished 554806784\n",
      "MPS Total allocated memory by driver (bytes): finished 12800884736\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.001038 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.000300 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9988603904\n",
      "Elapsed time: 0.002783 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13874626560\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.003840 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.096069 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10101850112\n",
      "Elapsed time: 0.054293 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13987872768\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.001349 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.000497 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9988603904\n",
      "Elapsed time: 0.068618 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13874626560\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.002900 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.060357 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 12926713856\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9028108288\n",
      "Elapsed time: 0.001719 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 12914130944\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.000581 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.010486 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9988603904\n",
      "Elapsed time: 0.025627 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13874626560\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.002745 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.030488 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 12926713856\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9028108288\n",
      "Elapsed time: 0.002389 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 12914130944\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.000569 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.012273 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10101850112\n",
      "Elapsed time: 0.006792 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13874626560\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.001937 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.058166 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10101850112\n",
      "Elapsed time: 0.093439 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13987872768\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.000767 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.000420 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10101850112\n",
      "Elapsed time: 0.162788 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13987872768\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.000470 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.086320 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9988603904\n",
      "Elapsed time: 0.044881 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13874626560\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 729603584\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10001186816\n",
      "Elapsed time: 0.001140 seconds\n",
      "MPS Memory currently allocated (bytes): finished 817001984\n",
      "MPS Total allocated memory by driver (bytes): finished 10114433024\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 481974784\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10114433024\n",
      "Elapsed time: 0.000423 seconds\n",
      "MPS Memory currently allocated (bytes): finished 525673984\n",
      "MPS Total allocated memory by driver (bytes): finished 14000455680\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 598505984\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 10101850112\n",
      "Elapsed time: 0.000973 seconds\n",
      "MPS Memory currently allocated (bytes): finished 642205184\n",
      "MPS Total allocated memory by driver (bytes): finished 13874626560\n",
      "MPS Memory currently allocated (bytes): after self.model() : 30530304\n",
      "MPS Total allocated memory by driver (bytes): after self.model(): 10001252352\n",
      "Reduced from 76 to 34 features\n",
      "Using torch.inference_mode for inference.\n",
      "MPS Memory currently allocated (bytes): before self.model() : 31395328\n",
      "MPS Total allocated memory by driver (bytes): before self.model(): 10001252352\n",
      "MPS Memory currently allocated (bytes): before transformer_encoder : 118315776\n",
      "MPS Total allocated memory by driver (bytes): before transformer_encoder: 10097770496\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 590267136\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9007251456\n",
      "Elapsed time: 0.003563 seconds\n",
      "MPS Memory currently allocated (bytes): finished 668925696\n",
      "MPS Total allocated memory by driver (bytes): finished 9053388800\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 367401216\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9053405184\n",
      "Elapsed time: 0.003189 seconds\n",
      "MPS Memory currently allocated (bytes): finished 406730496\n",
      "MPS Total allocated memory by driver (bytes): finished 12551454720\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 472279296\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9040822272\n",
      "Elapsed time: 0.062110 seconds\n",
      "MPS Memory currently allocated (bytes): finished 511608576\n",
      "MPS Total allocated memory by driver (bytes): finished 11762925568\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000485 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.040042 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 11741954048\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 8231321600\n",
      "Elapsed time: 0.004616 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 11729371136\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000334 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.005404 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000974 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000521 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.028748 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000661 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9237954560\n",
      "Elapsed time: 0.000637 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9330229248\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9330229248\n",
      "Elapsed time: 0.000249 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12828278784\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.041944 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000463 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.000941 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000377 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000300 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.000373 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000411 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000338 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.000849 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.036526 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000420 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.000519 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 11741954048\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 8243904512\n",
      "Elapsed time: 0.000334 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 11741954048\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.000707 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.005930 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 11741954048\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 8231321600\n",
      "Elapsed time: 0.000368 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 11729371136\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000308 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.009644 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000565 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 668925696\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9225371648\n",
      "Elapsed time: 0.000427 seconds\n",
      "MPS Memory currently allocated (bytes): finished 747584256\n",
      "MPS Total allocated memory by driver (bytes): finished 9317646336\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 446059776\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9317646336\n",
      "Elapsed time: 0.007877 seconds\n",
      "MPS Memory currently allocated (bytes): finished 485389056\n",
      "MPS Total allocated memory by driver (bytes): finished 12815695872\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 550937856\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 9305063424\n",
      "Elapsed time: 0.000921 seconds\n",
      "MPS Memory currently allocated (bytes): finished 590267136\n",
      "MPS Total allocated memory by driver (bytes): finished 12803112960\n",
      "MPS Memory currently allocated (bytes): after self.model() : 31031296\n",
      "MPS Total allocated memory by driver (bytes): after self.model(): 9225371648\n",
      "Reduced from 76 to 37 features\n",
      "Using torch.inference_mode for inference.\n",
      "MPS Memory currently allocated (bytes): before self.model() : 31031296\n",
      "MPS Total allocated memory by driver (bytes): before self.model(): 9225371648\n",
      "MPS Memory currently allocated (bytes): before transformer_encoder : 118418432\n",
      "MPS Total allocated memory by driver (bytes): before transformer_encoder: 9330229248\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 642808832\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 8239710208\n",
      "Elapsed time: 0.001514 seconds\n",
      "MPS Memory currently allocated (bytes): finished 730207232\n",
      "MPS Total allocated memory by driver (bytes): finished 8296333312\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 395180032\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 8296333312\n",
      "Elapsed time: 0.001648 seconds\n",
      "MPS Memory currently allocated (bytes): finished 438879232\n",
      "MPS Total allocated memory by driver (bytes): finished 19954401280\n",
      "share_kv_across_n_heads: 1\n",
      "MPS Memory currently allocated (bytes): before scaled_dot_product_attention 511711232\n",
      "MPS Total allocated memory by driver (bytes): before scaled_dot_product_attention 16055795712\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 1.04 GB, other allocations: 13.91 GB, max allowed: 18.13 GB). Tried to allocate 3.62 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:53\u001b[39m, in \u001b[36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _safe_call_with_telemetry(\n\u001b[32m     54\u001b[39m         func, args, kwargs, model_method, param_names\n\u001b[32m     55\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:97\u001b[39m, in \u001b[36m_safe_call_with_telemetry\u001b[39m\u001b[34m(func, args, kwargs, model_method, param_names)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Step 2: Run the actual function\u001b[39;00m\n\u001b[32m     96\u001b[39m start = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m result = func(*args, **kwargs)\n\u001b[32m     98\u001b[39m duration_ms = \u001b[38;5;28mint\u001b[39m((time.perf_counter() - start) * \u001b[32m1000\u001b[39m)\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Step 3: Send telemetry event\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/classifier.py:753\u001b[39m, in \u001b[36mTabPFNClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;129m@track_model_call\u001b[39m(model_method=\u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m, param_names=[\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: XType) -> np.ndarray:\n\u001b[32m    742\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict the probabilities of the classes for the provided input samples.\u001b[39;00m\n\u001b[32m    743\u001b[39m \n\u001b[32m    744\u001b[39m \u001b[33;03m    This is a wrapper around the `_predict_proba` method.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    751\u001b[39m \u001b[33;03m        Shape (n_samples, n_classes).\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_proba(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/classifier.py:766\u001b[39m, in \u001b[36mTabPFNClassifier._predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;129m@config_context\u001b[39m(transform_output=\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: XType) -> np.ndarray:\n\u001b[32m    757\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict the probabilities of the classes for the provided input samples.\u001b[39;00m\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    764\u001b[39m \u001b[33;03m        Shape (n_samples, n_classes).\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     proba_tensor = \u001b[38;5;28mself\u001b[39m._raw_predict(X, return_logits=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    767\u001b[39m     output = proba_tensor.float().detach().cpu().numpy()\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.interface_config_.USE_SKLEARN_16_DECIMAL_PRECISION:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/classifier.py:703\u001b[39m, in \u001b[36mTabPFNClassifier._raw_predict\u001b[39m\u001b[34m(self, X, return_logits)\u001b[39m\n\u001b[32m    700\u001b[39m     X = fix_dtypes(X, cat_indices=\u001b[38;5;28mself\u001b[39m.inferred_categorical_indices_)\n\u001b[32m    701\u001b[39m     X = process_text_na_dataframe(X, ord_encoder=\u001b[38;5;28mself\u001b[39m.preprocessor_)\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward(X, use_inference_mode=\u001b[38;5;28;01mTrue\u001b[39;00m, return_logits=return_logits)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/classifier.py:859\u001b[39m, in \u001b[36mTabPFNClassifier.forward\u001b[39m\u001b[34m(self, X, use_inference_mode, return_logits)\u001b[39m\n\u001b[32m    856\u001b[39m     \u001b[38;5;28mself\u001b[39m.executor_.use_torch_inference_mode(use_inference=use_inference_mode)\n\u001b[32m    858\u001b[39m outputs = []\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.executor_.iter_outputs(\n\u001b[32m    860\u001b[39m     X,\n\u001b[32m    861\u001b[39m     devices=\u001b[38;5;28mself\u001b[39m.devices_,\n\u001b[32m    862\u001b[39m     autocast=\u001b[38;5;28mself\u001b[39m.use_autocast_,\n\u001b[32m    863\u001b[39m ):\n\u001b[32m    864\u001b[39m     original_ndim = output.ndim\n\u001b[32m    866\u001b[39m     \u001b[38;5;66;03m# This block correctly handles both single configs and lists of configs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/inference.py:516\u001b[39m, in \u001b[36mInferenceEngineCachePreprocessing.iter_outputs\u001b[39m\u001b[34m(self, X, devices, autocast, only_return_standard_out)\u001b[39m\n\u001b[32m    513\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparallel_execute: Completed inference on ensemble members.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m model_forward_functions\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, \u001b[38;5;28mself\u001b[39m.ensemble_configs):\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m _move_and_squeeze_output(output, devices[\u001b[32m0\u001b[39m]), config\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference_mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/parallel_execute.py:59\u001b[39m, in \u001b[36mparallel_execute\u001b[39m\u001b[34m(devices, functions)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(devices) == \u001b[32m1\u001b[39m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOnly one device detected. Executing in the current thread.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _execute_in_current_thread(devices[\u001b[32m0\u001b[39m], functions)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _execute_with_multithreading(devices, functions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/parallel_execute.py:68\u001b[39m, in \u001b[36m_execute_in_current_thread\u001b[39m\u001b[34m(device, functions)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_in_current_thread\u001b[39m(\n\u001b[32m     65\u001b[39m     device: torch.device, functions: Iterable[ParallelFunction[R_co]]\n\u001b[32m     66\u001b[39m ) -> Generator[R_co]:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m function \u001b[38;5;129;01min\u001b[39;00m functions:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m function(device=device, is_parallel=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/inference.py:570\u001b[39m, in \u001b[36mInferenceEngineCachePreprocessing._call_model\u001b[39m\u001b[34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out)\u001b[39m\n\u001b[32m    567\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMPS Memory currently allocated (bytes): before self.model() :\u001b[39m\u001b[33m\"\u001b[39m, torch.mps.current_allocated_memory())\n\u001b[32m    568\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMPS Total allocated memory by driver (bytes): before self.model():\u001b[39m\u001b[33m\"\u001b[39m, torch.mps.driver_allocated_memory())\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m output = model(\n\u001b[32m    571\u001b[39m     X_full,\n\u001b[32m    572\u001b[39m     y_train,\n\u001b[32m    573\u001b[39m     only_return_standard_out=only_return_standard_out,\n\u001b[32m    574\u001b[39m     categorical_inds=batched_cat_ix,\n\u001b[32m    575\u001b[39m )\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.backends.mps.is_available():\n\u001b[32m    577\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMPS Memory currently allocated (bytes): after self.model() :\u001b[39m\u001b[33m\"\u001b[39m, torch.mps.current_allocated_memory())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/transformer.py:622\u001b[39m, in \u001b[36mPerFeatureTransformer.forward\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    619\u001b[39m     torch.mps.empty_cache()\n\u001b[32m    620\u001b[39m \u001b[38;5;66;03m# list_all_objects_memorize()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m encoder_out = \u001b[38;5;28mself\u001b[39m.transformer_encoder(\n\u001b[32m    623\u001b[39m     (\n\u001b[32m    624\u001b[39m         embedded_input\n\u001b[32m    625\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transformer_decoder\n\u001b[32m    626\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m embedded_input[:, :single_eval_pos]\n\u001b[32m    627\u001b[39m     ),\n\u001b[32m    628\u001b[39m     single_eval_pos=single_eval_pos,\n\u001b[32m    629\u001b[39m     cache_trainset_representation=\u001b[38;5;28mself\u001b[39m.cache_trainset_representation,\n\u001b[32m    630\u001b[39m )  \u001b[38;5;66;03m# b s f+1 e -> b s f+1 e\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m    632\u001b[39m     torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/transformer.py:99\u001b[39m, in \u001b[36mLayerStack.forward\u001b[39m\u001b[34m(self, x, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m         x = checkpoint(partial(layer, **kwargs), x, use_reentrant=\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         x = layer(x, **kwargs)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/layer.py:421\u001b[39m, in \u001b[36mPerFeatureEncoderLayer.forward\u001b[39m\u001b[34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    412\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPre-norm implementation is wrong, as the residual should never\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be layer normed here.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    414\u001b[39m     )\n\u001b[32m    415\u001b[39m     state = layer_norm(\n\u001b[32m    416\u001b[39m         state,\n\u001b[32m    417\u001b[39m         allow_inplace=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    418\u001b[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m state = sublayer(state)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pre_norm:\n\u001b[32m    423\u001b[39m     state = layer_norm(\n\u001b[32m    424\u001b[39m         state,\n\u001b[32m    425\u001b[39m         allow_inplace=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    426\u001b[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001b[32m    427\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/layer.py:335\u001b[39m, in \u001b[36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    332\u001b[39m     new_x_test = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_eval_pos:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     new_x_train = \u001b[38;5;28mself\u001b[39m.self_attn_between_items(\n\u001b[32m    336\u001b[39m         x[:, :single_eval_pos].transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m    337\u001b[39m         x[:, :single_eval_pos].transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m    338\u001b[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001b[32m    339\u001b[39m         cache_kv=cache_trainset_representation,\n\u001b[32m    340\u001b[39m         only_cache_first_head_kv=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    341\u001b[39m         add_input=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    342\u001b[39m         allow_inplace=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    343\u001b[39m         use_cached_kv=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    344\u001b[39m     ).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    346\u001b[39m     new_x_train = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/attention/full_attention.py:369\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv)\u001b[39m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m._k_cache = torch.empty(\n\u001b[32m    353\u001b[39m             batch_size,\n\u001b[32m    354\u001b[39m             seqlen_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    358\u001b[39m             dtype=x.dtype,\n\u001b[32m    359\u001b[39m         )\n\u001b[32m    360\u001b[39m         \u001b[38;5;28mself\u001b[39m._v_cache = torch.empty(\n\u001b[32m    361\u001b[39m             batch_size,\n\u001b[32m    362\u001b[39m             seqlen_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m             dtype=x.dtype,\n\u001b[32m    367\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m output: torch.Tensor = \u001b[38;5;28mself\u001b[39m._compute(\n\u001b[32m    370\u001b[39m     x,\n\u001b[32m    371\u001b[39m     x_kv,\n\u001b[32m    372\u001b[39m     \u001b[38;5;28mself\u001b[39m._k_cache,\n\u001b[32m    373\u001b[39m     \u001b[38;5;28mself\u001b[39m._v_cache,\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m._kv_cache,\n\u001b[32m    375\u001b[39m     cache_kv=cache_kv,\n\u001b[32m    376\u001b[39m     use_cached_kv=use_cached_kv,\n\u001b[32m    377\u001b[39m     add_input=add_input,\n\u001b[32m    378\u001b[39m     allow_inplace=allow_inplace,\n\u001b[32m    379\u001b[39m     save_peak_mem_factor=save_peak_mem_factor,\n\u001b[32m    380\u001b[39m     reuse_first_head_kv=reuse_first_head_kv,\n\u001b[32m    381\u001b[39m )\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output.reshape(x_shape_after_transpose[:-\u001b[32m1\u001b[39m] + output.shape[-\u001b[32m1\u001b[39m:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/memory.py:101\u001b[39m, in \u001b[36msupport_save_peak_mem_factor.<locals>.method_\u001b[39m\u001b[34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_input:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + method(\u001b[38;5;28mself\u001b[39m, x, *args, **kwargs)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/attention/full_attention.py:519\u001b[39m, in \u001b[36mMultiHeadAttention._compute\u001b[39m\u001b[34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Attention computation.\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[33;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    509\u001b[39m q, k, v, kv, qkv = \u001b[38;5;28mself\u001b[39m.compute_qkv(\n\u001b[32m    510\u001b[39m     x,\n\u001b[32m    511\u001b[39m     x_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    517\u001b[39m     reuse_first_head_kv=reuse_first_head_kv,\n\u001b[32m    518\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m attention_head_outputs = MultiHeadAttention.compute_attention_heads(\n\u001b[32m    520\u001b[39m     q,\n\u001b[32m    521\u001b[39m     k,\n\u001b[32m    522\u001b[39m     v,\n\u001b[32m    523\u001b[39m     kv,\n\u001b[32m    524\u001b[39m     qkv,\n\u001b[32m    525\u001b[39m     \u001b[38;5;28mself\u001b[39m.dropout_p,\n\u001b[32m    526\u001b[39m     \u001b[38;5;28mself\u001b[39m.softmax_scale,\n\u001b[32m    527\u001b[39m )\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.einsum(\n\u001b[32m    529\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m... h d, h d s -> ... s\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    530\u001b[39m     attention_head_outputs,\n\u001b[32m    531\u001b[39m     \u001b[38;5;28mself\u001b[39m._w_out,\n\u001b[32m    532\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/TabPFN_Sparse/src/tabpfn_ext/architectures/base/attention/full_attention.py:756\u001b[39m, in \u001b[36mMultiHeadAttention.compute_attention_heads\u001b[39m\u001b[34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001b[39m\n\u001b[32m    753\u001b[39m     torch.mps.empty_cache()\n\u001b[32m    755\u001b[39m start = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m attention_head_outputs = torch.nn.functional.scaled_dot_product_attention(\n\u001b[32m    757\u001b[39m     q_cont,\n\u001b[32m    758\u001b[39m     k_cont,\n\u001b[32m    759\u001b[39m     v_cont,\n\u001b[32m    760\u001b[39m     \u001b[38;5;66;03m# attn_mask=attn_mask,\u001b[39;00m\n\u001b[32m    761\u001b[39m     dropout_p=dropout_p,\n\u001b[32m    762\u001b[39m     **extra_inputs,\n\u001b[32m    763\u001b[39m )\n\u001b[32m    764\u001b[39m end = time.perf_counter()\n\u001b[32m    765\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mElapsed time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 1.04 GB, other allocations: 13.91 GB, max allowed: 18.13 GB). Tried to allocate 3.62 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict probabilities\n",
    "prediction_probabilities = clf.predict_proba(X_test)\n",
    "\n",
    "# print(prediction_probabilities)\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, prediction_probabilities[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3feb1934-175b-4910-ad85-110e274bf651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7156, 0.0431, 0.0466,  ..., 0.4632, 0.0519, 0.8376],\n",
      "        [0.8305, 0.1702, 0.0688,  ..., 0.3416, 0.5009, 0.7858],\n",
      "        [0.8889, 0.3182, 0.2094,  ..., 0.5747, 0.8757, 0.8355],\n",
      "        ...,\n",
      "        [0.2162, 0.0302, 0.6480,  ..., 0.7783, 0.8364, 0.1507],\n",
      "        [0.6451, 0.0922, 0.4995,  ..., 0.0951, 0.4936, 0.3479],\n",
      "        [0.4806, 0.2587, 0.2407,  ..., 0.1417, 0.6283, 0.8042]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "# Example tensor: shape (num_rows, num_columns)\n",
    "tensor = torch.rand(10000, 500) \n",
    "\n",
    "# Convert columns to numpy arrays, hash each one\n",
    "def hash_tensor_column(col):\n",
    "    col_bytes = col.numpy().tobytes()  # Convert to bytes\n",
    "    return hashlib.md5(col_bytes).hexdigest()\n",
    "\n",
    "# Transpose to iterate over columns\n",
    "cols = tensor.t()\n",
    "hashes = [hash_tensor_column(col) for col in cols]\n",
    "_, unique_indices = np.unique(hashes, return_index=True)\n",
    "unique_indices_sorted = sorted(unique_indices)\n",
    "\n",
    "# Get tensor with unique columns only\n",
    "unique_tensor = tensor[:, unique_indices_sorted]\n",
    "\n",
    "print(unique_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0d8319-2c7b-4cff-8a4d-a2186869589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500])\n"
     ]
    }
   ],
   "source": [
    "print(unique_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c6617ca-ab30-4188-a5da-97020fbbe143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example tensor X of shape (num_samples, num_features)\n",
    "def remove_correlated(tensor):\n",
    "    X = tensor # for example\n",
    "    \n",
    "    # Normalize columns to unit norm\n",
    "    X_norm = X / X.norm(dim=0, keepdim=True)\n",
    "    \n",
    "    # Compute cosine similarity matrix between columns (features)\n",
    "    sim_matrix = torch.matmul(X_norm.T, X_norm)  # shape (num_features, num_features)\n",
    "    \n",
    "    # Threshold and remove highly similar columns\n",
    "    threshold = 0.97\n",
    "    to_remove = set()\n",
    "    n_features = X.shape[1]\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            if sim_matrix[i, j] > threshold:\n",
    "                to_remove.add(j)\n",
    "    \n",
    "    selected_indices = [i for i in range(n_features) if i not in to_remove]\n",
    "    X_reduced = X[:, selected_indices]\n",
    "    \n",
    "    print(f\"Original shape: {X.shape}, Reduced shape: {X_reduced.shape}\")\n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6aa792-25e0-4003-a72e-c563187f2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 500])\n",
      "tensor([[1.0000, 0.9959, 0.9696, 0.9850, 0.9854],\n",
      "        [0.9959, 1.0000, 0.9736, 0.9890, 0.9895],\n",
      "        [0.9696, 0.9736, 1.0000, 0.9630, 0.9634],\n",
      "        [0.9850, 0.9890, 0.9630, 1.0000, 0.9786],\n",
      "        [0.9854, 0.9895, 0.9634, 0.9786, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "n_features = 500\n",
    "\n",
    "base_col = torch.randn(n_samples, 1)  # base column vector\n",
    "\n",
    "# Define a noise vector with a different noise scale per column\n",
    "noise_scales = torch.rand(n_features) * 0.3  # e.g., noise std dev between 0 and 0.1\n",
    "\n",
    "# Generate noise matrix with shape (n_samples, n_features)\n",
    "noise = torch.randn(n_samples, n_features) * noise_scales  # automatically broadcasts noise_scales along rows\n",
    "\n",
    "# Add different noise to each column based on noise_scales\n",
    "correlated_matrix = base_col + noise\n",
    "\n",
    "print(correlated_matrix.shape)  # (10000, 500)\n",
    "\n",
    "# Check correlation for a few columns\n",
    "corr_matrix = torch.corrcoef(correlated_matrix.T)\n",
    "print(corr_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "740200c6-2a94-4612-9dfa-3ee83ea28471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([100000, 500]), Reduced shape: torch.Size([100000, 75])\n"
     ]
    }
   ],
   "source": [
    "decorrelated = remove_correlated(correlated_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2498be1-b73e-4d98-b2f0-78beb1c0b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9650, 0.9579, 0.9595, 0.9608],\n",
      "        [0.9650, 1.0000, 0.9242, 0.9260, 0.9285],\n",
      "        [0.9579, 0.9242, 1.0000, 0.9194, 0.9203],\n",
      "        [0.9595, 0.9260, 0.9194, 1.0000, 0.9206],\n",
      "        [0.9608, 0.9285, 0.9203, 0.9206, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Check correlation for a few columns\n",
    "corr_matrix = torch.corrcoef(decorrelated.T)\n",
    "print(corr_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756856c6-6801-44fa-8d7a-df1a629dc563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(((1.667167937838927, 0.021067031196282046, -1.062389766586226, 0.8979769559205804, -0.3764693010382622, 1.0078820241854531, -0.24545000742959602, -1.8523442913582666, 0.9627946690861312, 0.3524175620598159, -0.9837872669723638, -0.7807438783884271, 0.06453263048717099, -0.1041605134264547, -0.9490586572622636, -0.5849740918675714, 0.28279364840032156, -0.6265301049087184, -0.06310669563379105, 0.9705159090538583, -1.386804448968495, -0.28505150376691546, 0.15862447226955062, 0.12473856688652137, 0.5403121434146622, -0.11515326571618022, -1.1345211234738783, 1.5609355143826595, 1.2075505901879295, -1.0984225662049683, 0.4168341126398801, 0.33829729368802586, 0.5144166594458067, 0.4791669511738508, 0.04392825343323537, -0.79776782034572, -0.3730989866009799, 0.884342611828041, -0.963405493031893, -0.31996843692828947, -1.689558273797796, 0.8711025657386609, 0.028292643499445748, 0.2471200411234564, 0.7516905883722862, -0.6177278300382819, -1.0218012699801535, -0.3191782842995634, -0.6666759347473361, -1.902067011172227, 0.09056910323101389, 0.7278739427291535, -0.13711521295115653, 0.35107705535347555, -0.0738694861885245, 0.17090240571742396, 0.7597199370226508, -0.06133567113984848, -0.08026053817825456, -1.3387151854792447, 0.5998447791721427, -1.3641777094586376, -0.5026934338196163, -0.026670866979974873, 0.5101865473413163, -0.9765840096652317, 0.24657834541410345, -1.8844286891582327, 0.236968886858507, -1.555789673655654, 0.5696467755925967, 0.3626342037615739, -0.4158345671912819, -1.3915894625539171, 0.3577950648668241, -0.07304264533270287, 0.6157279564957284, -0.1489318067927555, -1.446906270904652, 0.4988704088445191, 0.7943794459316527, 0.2621459222474931, 1.087912622574552, -0.40253504110185273, 2.2180722700978035, -0.16811537278287494, 0.1811476745730369, -0.9839162581629048, -0.03592458754073537, 1.3863512528425148, 2.509963135562142, -1.0165041114003075, 0.6206025492825474, 0.03977687943801514, -0.8548552188620673, 1.718781384525649, 0.6617644694586767, -0.9757457242899334, 2.3703611182020645, -1.0512218755593734, 2.2008756406872547, 0.8496699782768745, 0.030318642101319827, 0.03143489983867084, 0.6921833240587308, 0.23857069982469484, -0.15504183072061933, -1.8212879728620137, -0.4821309801893084, 0.1427206911770736, -0.6764760337418629, 0.8049422972935639, 0.29969860455999026, 0.32583602562555986, 0.41487598343601917, 0.47701233585364317, 0.8133747357811838, -0.30755173725726864, 1.0354284590805505, 0.11339489703574512, -1.1418013409305015, 1.701477543645146, 0.9381239930571469, -1.0509561078934921, -0.7209681526466069, 1.4742137052414022, -0.29310382270753377, 0.08488753432399115), 1), np.float64(0.0))]\n"
     ]
    }
   ],
   "source": [
    "from lshashpy3 import LSHash\n",
    "import numpy as np\n",
    "\n",
    "# Initialize LSH for vectors of dimension 128, with 10 hash tables (num_hashtables)\n",
    "lsh = LSHash(hash_size=8, input_dim=128, num_hashtables=5)\n",
    "\n",
    "# Add data points (vectors)\n",
    "vector = np.random.randn(128)\n",
    "# print(vector)\n",
    "lsh.index(vector, extra_data = 1)\n",
    "\n",
    "# Query for nearest neighbors\n",
    "query = np.random.randn(128)\n",
    "results = lsh.query(vector, num_results=100)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dd4add-a845-462a-80bd-d217676a88e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Predict labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predictions = clf.predict(X_test)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m, accuracy_score(y_test, predictions))\n",
      "\u001b[31mNameError\u001b[39m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict labels\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"Accuracy\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3c0a7a-b651-4f70-bbbc-b2c8eb6b4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165296b3-8365-4d5b-b549-76784de3a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 10000  # size of dataset\n",
    "N = 1000           # chunk size\n",
    "\n",
    "indices_chunks = [range(i, min(i + N, max_index)) for i in range(0, max_index, N)]\n",
    "indices_chunks = [np.array(chunk) for chunk in indices_chunks]\n",
    "indices_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd1c7542-94dd-44aa-ad14-993e63ffcbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new tensor was created at /var/folders/sg/nff54zj50zl8mzy2j3lnw34w0000gn/T/ipykernel_97458/3516784111.py:23\n",
      "Tensor: tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import inspect\n",
    "\n",
    "# Save the original __new__ method\n",
    "original_new = torch._C._TensorBase.__new__\n",
    "\n",
    "def custom_new(cls, *args, **kwargs):\n",
    "    # Get caller frame info (1 level above current)\n",
    "    frame = inspect.stack()[1]\n",
    "    filename = frame.filename\n",
    "    lineno = frame.lineno\n",
    "\n",
    "    # Call the original __new__ to create instance\n",
    "    instance = original_new(cls, *args, **kwargs)\n",
    "\n",
    "    print(f\"A new tensor was created at {filename}:{lineno}\\nTensor: {instance}\")\n",
    "    return instance\n",
    "\n",
    "# Monkey patch torch.Tensor.__new__\n",
    "torch.Tensor.__new__ = custom_new\n",
    "\n",
    "# Test tensor creation to see file and line number\n",
    "t = torch.Tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbabcd-4285-4b0e-802a-15849c33f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b22150-561c-4a1e-8171-c04ac426301b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deil/Development/tabpfn-extensions/src/tabpfn_extensions/post_hoc_ensembles/sklearn_interface.py:156: UserWarning: CUDA device requested but 'tabpfn' package not found. Falling back to CPU as the client-based API does not support GPU.\n",
      "  self.device_ = infer_device_and_type(self.device)\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to save metadata file due to exception 'NoneType' object has no attribute 'lower', skipping...\n",
      "\tWARNING: Running TabPFNv2 on CPU. This can be very slow. We recommend using a GPU instead.\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn/classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n",
      "\tWARNING: Running TabPFNv2 on CPU. This can be very slow. We recommend using a GPU instead.\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn/classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n",
      "\tWARNING: Running TabPFNv2 on CPU. This can be very slow. We recommend using a GPU instead.\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn/classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n",
      "\tWARNING: Running TabPFNv2 on CPU. This can be very slow. We recommend using a GPU instead.\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn/classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n",
      "\tWARNING: Running TabPFNv2 on CPU. This can be very slow. We recommend using a GPU instead.\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn/classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n",
      "\tWARNING: Running TabPFNv2 on CPU. This can be very slow. We recommend using a GPU instead.\n",
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tabpfn/classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n",
      "Warning: AutoGluon did not successfully train any models\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m clf = AutoTabPFNClassifier(max_time=\u001b[32m120\u001b[39m, device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# 120 seconds tuning time\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clf.fit(X_train, y_train)\n\u001b[32m      3\u001b[39m predictions = clf.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/tabpfn-extensions/src/tabpfn_extensions/post_hoc_ensembles/sklearn_interface.py:395\u001b[39m, in \u001b[36mAutoTabPFNClassifier.fit\u001b[39m\u001b[34m(self, X, y, categorical_feature_indices, feature_names)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;66;03m# Normal case - multiple classes with sufficient samples per class\u001b[39;00m\n\u001b[32m    394\u001b[39m \u001b[38;5;28mself\u001b[39m.single_class_ = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28msuper\u001b[39m().fit(X, y_encoded)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/tabpfn-extensions/src/tabpfn_extensions/post_hoc_ensembles/sklearn_interface.py:255\u001b[39m, in \u001b[36mAutoTabPFNBase.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device_.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    253\u001b[39m     num_gpus = torch.cuda.device_count()\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m \u001b[38;5;28mself\u001b[39m.predictor_.fit(\n\u001b[32m    256\u001b[39m     train_data=training_df,\n\u001b[32m    257\u001b[39m     time_limit=\u001b[38;5;28mself\u001b[39m.max_time,\n\u001b[32m    258\u001b[39m     presets=\u001b[38;5;28mself\u001b[39m.presets,\n\u001b[32m    259\u001b[39m     hyperparameters=hyperparameters,\n\u001b[32m    260\u001b[39m     num_gpus=num_gpus,\n\u001b[32m    261\u001b[39m     **\u001b[38;5;28mself\u001b[39m._get_predictor_fit_args(),\n\u001b[32m    262\u001b[39m )\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# Set sklearn required attributes from the fitted predictor\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor_.features())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/autogluon/core/utils/decorators.py:31\u001b[39m, in \u001b[36munpack.<locals>._unpack_inner.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args, **kwargs):\n\u001b[32m     30\u001b[39m     gargs, gkwargs = g(*other_args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*gargs, **gkwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1363\u001b[39m, in \u001b[36mTabularPredictor.fit\u001b[39m\u001b[34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1360\u001b[39m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28mself\u001b[39m._fit_strategy = fit_strategy\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m \u001b[38;5;28mself\u001b[39m._fit(ag_fit_kwargs=ag_fit_kwargs, ag_post_fit_kwargs=ag_post_fit_kwargs)\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1371\u001b[39m, in \u001b[36mTabularPredictor._fit\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[39m\n\u001b[32m   1369\u001b[39m \u001b[38;5;28mself\u001b[39m._learner.fit(**ag_fit_kwargs)\n\u001b[32m   1370\u001b[39m \u001b[38;5;28mself\u001b[39m._set_post_fit_vars()\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28mself\u001b[39m._post_fit(**ag_post_fit_kwargs)\n\u001b[32m   1372\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1703\u001b[39m, in \u001b[36mTabularPredictor._post_fit\u001b[39m\u001b[34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit, num_cpus, num_gpus, refit_full_kwargs, fit_strategy, raise_on_no_models_fitted)\u001b[39m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_names():\n\u001b[32m   1702\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_no_models_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1703\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNo models were trained successfully during fit().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Inspect the log output or increase verbosity to determine why no models were fit.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1707\u001b[39m         )\n\u001b[32m   1709\u001b[39m     logger.log(\u001b[32m30\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWarning: No models found, skipping post_fit logic...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call."
     ]
    }
   ],
   "source": [
    "clf = AutoTabPFNClassifier(max_time=120, device=\"cuda\") # 120 seconds tuning time\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a15ae1-bc52-4c3e-a5ed-b3c31d0a3196",
   "metadata": {},
   "source": [
    "The \"dataset-specific preprocessings\" mentioned for TabPFN refer to various data preparation techniques that can improve the model’s performance beyond its default capabilities. While TabPFN can handle raw tabular data with minimal preprocessing—\n",
    "automatically managing\n",
    "- missing values,\n",
    "- encoding categorical variables,\n",
    "- and normalizing features—performance\n",
    "\n",
    "can be enhanced by applying specific preprocessing steps based on the characteristics of the dataset.\n",
    "\n",
    "These preprocessing techniques include:\n",
    "\n",
    "- Zero-padding features to a fixed input dimensionality if the dataset has fewer features than expected.\n",
    "\n",
    "- Applying transformations (e.g., power transforms like Yeo–Johnson) to make feature distributions closer to normal, which suits the model’s assumptions.\n",
    "\n",
    "- Quantile transformation where inputs are quantized to evenly spaced values, often doubling features by keeping original copies.\n",
    "\n",
    "- Category shuffling for categorical features with low cardinality, which helps generalization.\n",
    "\n",
    "- Outlier removal to discard extreme values far from the mean.\n",
    "\n",
    "- Adding compressed feature representations like SVD components.\n",
    "\n",
    "- Using domain knowledge to combine or remove less relevant features.\n",
    "\n",
    "- Grouping data based on random forests for heterogeneous datasets, splitting into homogeneous subsets.\n",
    "\n",
    "These preprocessings tailor the data better for TabPFN’s neural architecture, which expects roughly normally distributed features after transformation, and can significantly boost accuracy, especially when manually tuned or used with hyperparameter optimization techniques. They also aid in adapting TabPFN to larger datasets and more complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1b7b2-bbc4-48a5-8cbb-515376dba933",
   "metadata": {},
   "source": [
    "## BlockMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78412b29-6d7e-40b1-8ed7-e7a168ee0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.attention.flex_attention import flex_attention, create_block_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd6fa9d-1c32-4582-b21f-9944638788ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m q_idx >= kv_idx\n\u001b[32m      4\u001b[39m sed_len_kv = \u001b[32m4\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m block_mask = create_block_mask(causal_mask, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, sed_len_kv, sed_len_kv)\n\u001b[32m      8\u001b[39m query = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, sed_len_kv, \u001b[32m64\u001b[39m, dtype=torch.float32)\n\u001b[32m      9\u001b[39m key = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, sed_len_kv, \u001b[32m64\u001b[39m, dtype=torch.float32)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:887\u001b[39m, in \u001b[36mcreate_block_mask\u001b[39m\u001b[34m(mask_mod, B, H, Q_LEN, KV_LEN, device, BLOCK_SIZE, _compile)\u001b[39m\n\u001b[32m    879\u001b[39m     warnings.warn(\n\u001b[32m    880\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_compile flag on create_block_mask was originally added to work around a torch.compile limitation. That limitation has since been addressed. So, to compile create_block_mask, we suggest doing torch.compile(create_block_mask). This still works for now, but will be removed in the future.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    881\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    882\u001b[39m     )\n\u001b[32m    883\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.compile(create_block_mask)(\n\u001b[32m    884\u001b[39m         mask_mod, B, H, Q_LEN, KV_LEN, device, BLOCK_SIZE\n\u001b[32m    885\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m mask_tensor = create_mask(mask_mod, B, H, Q_LEN, KV_LEN, device)\n\u001b[32m    888\u001b[39m partial_block_mask, full_block_mask = _convert_mask_to_block_mask(\n\u001b[32m    889\u001b[39m     mask_tensor,\n\u001b[32m    890\u001b[39m     Q_BLOCK_SIZE=Q_BLOCK_SIZE,\n\u001b[32m    891\u001b[39m     KV_BLOCK_SIZE=KV_BLOCK_SIZE,\n\u001b[32m    892\u001b[39m     separate_full_blocks=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    893\u001b[39m )\n\u001b[32m    894\u001b[39m block_mask = _create_sparse_block_from_block_mask(\n\u001b[32m    895\u001b[39m     (partial_block_mask, full_block_mask),\n\u001b[32m    896\u001b[39m     mask_mod,\n\u001b[32m   (...)\u001b[39m\u001b[32m    899\u001b[39m     KV_BLOCK_SIZE,\n\u001b[32m    900\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:802\u001b[39m, in \u001b[36mcreate_mask\u001b[39m\u001b[34m(mod_fn, B, H, Q_LEN, KV_LEN, device)\u001b[39m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m H \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    801\u001b[39m     H = \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m b = torch.arange(\u001b[32m0\u001b[39m, B, device=device)\n\u001b[32m    803\u001b[39m h = torch.arange(\u001b[32m0\u001b[39m, H, device=device)\n\u001b[32m    804\u001b[39m m = torch.arange(\u001b[32m0\u001b[39m, Q_LEN, device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/torch/cuda/__init__.py:363\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    361\u001b[39m     )\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def causal_mask(b, h, q_idx, kv_idx):\n",
    "    return q_idx >= kv_idx\n",
    "\n",
    "sed_len_kv = 4\n",
    "\n",
    "\n",
    "block_mask = create_block_mask(causal_mask, 1, 1, sed_len_kv, sed_len_kv)\n",
    "query = torch.randn(1, 1, sed_len_kv, 64, dtype=torch.float16)\n",
    "key = torch.randn(1, 1, sed_len_kv, 64, dtype=torch.float16)\n",
    "value = torch.randn(1, 1, sed_len_kv, 64, dtype=torch.float16)\n",
    "output = flex_attention(query, key, value, block_mask=block_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce19d3d-12f3-48fd-b5cd-6f9f07eb51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0, 0)\n",
    "██    \n",
    "████  \n",
    "██████\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b69c58c9-0584-443f-ae06-2bafc0476abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 500])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlated_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f816a6a-a579-4ef6-93fb-8f64f4202836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/nff54zj50zl8mzy2j3lnw34w0000gn/T/ipykernel_97458/3193281946.py:12: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  data_norm = data / np.linalg.norm(data, axis=0, keepdims=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m data_norm = data / np.linalg.norm(data, axis=\u001b[32m0\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Transpose to treat columns as vectors: shape (n_features, n_samples)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m vectors = data_norm.T.copy()\n\u001b[32m     17\u001b[39m d = vectors.shape[\u001b[32m1\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Build FAISS index on columns as vectors\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Example data: 10000 samples, 128 features (columns)\n",
    "n_samples, n_features = 10000, 128\n",
    "np.random.seed(1234)\n",
    "data = np.random.random((n_samples, n_features)).astype('float32')\n",
    "\n",
    "# Normalize columns to unit length for cosine similarity\n",
    "data_norm = data / np.linalg.norm(data, axis=0, keepdims=True)\n",
    "\n",
    "# Transpose to treat columns as vectors: shape (n_features, n_samples)\n",
    "vectors = data_norm.T.copy()\n",
    "\n",
    "d = vectors.shape[1]\n",
    "\n",
    "# Build FAISS index on columns as vectors\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(vectors)\n",
    "\n",
    "# Query one or more columns similarly as vectors: e.g., first 3 columns\n",
    "query_vectors = vectors[:3]\n",
    "\n",
    "# Similarity threshold\n",
    "threshold = 0.9\n",
    "\n",
    "# Perform range search to find all columns with similarity >= threshold\n",
    "distances, indices = index.range_search(query_vectors, threshold)\n",
    "\n",
    "print(\"Indices of similar columns within threshold:\", indices)\n",
    "print(\"Similarity scores:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a614193e-fb25-41dd-bd86-c19391ed7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/nff54zj50zl8mzy2j3lnw34w0000gn/T/ipykernel_97458/2222696753.py:12: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  data_norm = data / np.linalg.norm(data, axis=0, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of column 1: ([1, 38, 466, 189, 44, 376, 106, 236, 305, 287], [0.0, 0.006505327764898539, 0.007564406376332045, 0.007712687365710735, 0.00787327066063881, 0.007918594405055046, 0.007926102727651596, 0.008372271433472633, 0.008597083389759064, 0.009003445506095886])\n",
      "Neighbors of column 10: ([10, 466, 44, 189, 106, 236, 376, 41, 38, 196], [0.0, 0.009036474861204624, 0.009206357412040234, 0.00941762700676918, 0.009808232076466084, 0.009832514449954033, 0.010236445814371109, 0.01024224516004324, 0.01025389414280653, 0.010950976982712746])\n",
      "Neighbors of column 16: ([16, 466, 236, 106, 189, 38, 44, 376, 305, 41], [0.0, 0.00810456182807684, 0.0082213981077075, 0.008243114687502384, 0.008293597027659416, 0.008407790213823318, 0.008534412831068039, 0.00856233760714531, 0.009108764119446278, 0.009935025125741959])\n",
      "Neighbors of column 22: ([22, 38, 466, 106, 189, 376, 236, 44, 305, 41], [0.0, 0.024791991338133812, 0.02481597661972046, 0.024880751967430115, 0.024966904893517494, 0.024976439774036407, 0.025016941130161285, 0.02507399208843708, 0.025209227576851845, 0.02529885806143284])\n",
      "Neighbors of column 30: ([30, 189, 38, 236, 466, 106, 44, 376, 196, 305], [0.0, 0.020265143364667892, 0.020338520407676697, 0.02046995609998703, 0.020472848787903786, 0.020856477320194244, 0.020919211208820343, 0.021174175664782524, 0.02123597078025341, 0.021241629496216774])\n",
      "Neighbors of column 38: ([38, 44, 106, 189, 236, 466, 305, 376, 196, 41], [0.0, 0.00154407590162009, 0.0015440791612491012, 0.002156194532290101, 0.0029092696495354176, 0.0032018693163990974, 0.004256741143763065, 0.00451495498418808, 0.005050813779234886, 0.0058593666180968285])\n",
      "Neighbors of column 41: ([41, 376, 106, 38, 466, 189, 44, 236, 305, 287], [0.0, 0.005787723697721958, 0.0058185262605547905, 0.0058593666180968285, 0.005889794789254665, 0.005920093506574631, 0.00732418242841959, 0.007540727034211159, 0.007697202265262604, 0.008170482702553272])\n",
      "Neighbors of column 43: ([43, 106, 189, 236, 44, 466, 305, 376, 38, 41], [0.0, 0.012255726382136345, 0.01251086127012968, 0.012515600770711899, 0.012591535225510597, 0.012638804502785206, 0.01277020014822483, 0.012793514877557755, 0.012904838658869267, 0.01401626318693161])\n",
      "Neighbors of column 44: ([44, 38, 189, 376, 236, 106, 466, 305, 287, 196], [0.0, 0.00154407590162009, 0.001891101012006402, 0.0031265169382095337, 0.003347473917528987, 0.0036211740225553513, 0.003782191313803196, 0.004284639377146959, 0.005609896965324879, 0.006098601501435041])\n",
      "Neighbors of column 54: ([54, 106, 236, 466, 189, 44, 376, 38, 305, 41], [0.0, 0.007126232143491507, 0.007142944261431694, 0.007493167649954557, 0.007564440835267305, 0.007689446676522493, 0.00812663696706295, 0.008631688542664051, 0.009568341076374054, 0.010036525316536427])\n",
      "Neighbors of column 74: ([74, 189, 236, 466, 44, 38, 106, 376, 305, 287], [0.0, 0.01485853549093008, 0.014898568391799927, 0.014990286901593208, 0.01506562065333128, 0.015266111120581627, 0.015301189385354519, 0.015378928743302822, 0.015390554443001747, 0.015814557671546936])\n",
      "Neighbors of column 88: ([88, 466, 189, 236, 38, 44, 106, 376, 287, 305], [0.0, 0.01250606682151556, 0.012567908503115177, 0.012699982151389122, 0.013001477345824242, 0.013047195971012115, 0.013120113871991634, 0.01368494052439928, 0.0139138363301754, 0.014139088802039623])\n",
      "Neighbors of column 103: ([103, 189, 466, 44, 236, 376, 38, 106, 287, 305], [0.0, 0.02275884710252285, 0.02285286970436573, 0.022917943075299263, 0.022928403690457344, 0.02301924116909504, 0.02310967817902565, 0.023112226277589798, 0.023292042315006256, 0.023325340822339058])\n",
      "Neighbors of column 106: ([466, 106, 189, 38, 305, 236, 44, 376, 287, 196], [0.0, 0.0, 0.0, 0.0015440791612491012, 0.0018269802676513791, 0.002990093780681491, 0.0036211740225553513, 0.003996752202510834, 0.005326504819095135, 0.005535035859793425])\n",
      "Neighbors of column 112: ([112, 189, 466, 236, 106, 38, 44, 376, 305, 196], [0.0, 0.011256971396505833, 0.01143033429980278, 0.011451184749603271, 0.011492744088172913, 0.01183514017611742, 0.011840133927762508, 0.01211389247328043, 0.012138471007347107, 0.01239596214145422])\n",
      "Neighbors of column 113: ([113, 236, 106, 44, 38, 376, 189, 466, 305, 196], [0.0, 0.008206915110349655, 0.008272017352283001, 0.008393600583076477, 0.008393630385398865, 0.008414911106228828, 0.008721011690795422, 0.008748283609747887, 0.008950370363891125, 0.009741188026964664])\n",
      "Neighbors of column 121: ([121, 236, 189, 466, 106, 44, 38, 305, 376, 287], [0.0, 0.006982590537518263, 0.0075170062482357025, 0.0076894513331353664, 0.007751218043267727, 0.007812477182596922, 0.00782012939453125, 0.00783536396920681, 0.008293606340885162, 0.008870059624314308])\n",
      "Neighbors of column 130: ([130, 466, 106, 189, 44, 236, 38, 376, 305, 196], [0.0, 0.0072752078995108604, 0.007397082168608904, 0.007429261226207018, 0.008067695423960686, 0.008082479238510132, 0.008485415950417519, 0.008631671778857708, 0.00884314812719822, 0.009618001990020275])\n",
      "Neighbors of column 148: ([148, 106, 305, 466, 189, 376, 38, 44, 236, 287], [0.0, 0.011860277503728867, 0.012487013824284077, 0.012506062164902687, 0.012610514648258686, 0.012723439373075962, 0.01288172509521246, 0.012886306270956993, 0.012895587831735611, 0.013354250229895115])\n",
      "Neighbors of column 174: ([174, 376, 38, 236, 466, 189, 106, 44, 305, 41], [0.0, 0.011383350007236004, 0.011529023759067059, 0.011688184924423695, 0.011799830012023449, 0.01180996187031269, 0.012138464488089085, 0.012275159358978271, 0.012746863067150116, 0.012779523618519306])\n",
      "Neighbors of column 182: ([182, 236, 466, 189, 44, 106, 376, 38, 305, 41], [0.0, 0.02769893780350685, 0.027802009135484695, 0.0278213769197464, 0.027879035100340843, 0.027947425842285156, 0.028019897639751434, 0.02808787114918232, 0.02821492776274681, 0.028500715270638466])\n",
      "Neighbors of column 187: ([187, 189, 466, 44, 38, 106, 305, 236, 376, 41], [0.0, 0.022468963637948036, 0.022545699030160904, 0.022614292800426483, 0.022656502202153206, 0.02269064635038376, 0.022758888080716133, 0.022847725078463554, 0.023181846365332603, 0.0232382919639349])\n",
      "Neighbors of column 189: ([466, 236, 106, 189, 44, 38, 305, 376, 287, 196], [0.0, 0.0, 0.0, 0.0, 0.001891101012006402, 0.002156194532290101, 0.0025837465655058622, 0.0031074085272848606, 0.005459148436784744, 0.0057256040163338184])\n",
      "Neighbors of column 196: ([196, 38, 466, 106, 189, 44, 236, 376, 305, 41], [0.0, 0.005050813779234886, 0.005480926483869553, 0.005535035859793425, 0.0057256040163338184, 0.006098601501435041, 0.006403734441846609, 0.006783414166420698, 0.007101088762283325, 0.008221390657126904])\n",
      "Neighbors of column 207: ([207, 189, 236, 106, 38, 466, 376, 305, 44, 196], [0.0, 0.018803555518388748, 0.018832026049494743, 0.018914127722382545, 0.018992774188518524, 0.019080407917499542, 0.019080452620983124, 0.019307149574160576, 0.01939639076590538, 0.019488397985696793])\n",
      "Neighbors of column 213: ([213, 189, 236, 466, 106, 38, 376, 44, 41, 305], [0.0, 0.025388257578015327, 0.025406982749700546, 0.025409303605556488, 0.025521663948893547, 0.0255357064306736, 0.02555905096232891, 0.025631140917539597, 0.02576339617371559, 0.025848913937807083])\n",
      "Neighbors of column 219: ([219, 466, 189, 44, 106, 236, 376, 196, 38, 305], [0.0, 0.01083608902990818, 0.010918316431343555, 0.011341341771185398, 0.011435573920607567, 0.011435579508543015, 0.01151868887245655, 0.012039856985211372, 0.012054719030857086, 0.01226549781858921])\n",
      "Neighbors of column 235: ([235, 189, 44, 236, 376, 466, 106, 38, 287, 41], [0.0, 0.009574539959430695, 0.010591259226202965, 0.010602535679936409, 0.010641830042004585, 0.010814041830599308, 0.01089093741029501, 0.01096730399876833, 0.011235736310482025, 0.011970320716500282])\n",
      "Neighbors of column 236: ([189, 236, 466, 376, 38, 106, 44, 305, 287, 196], [0.0, 0.0, 0.0017605188768357038, 0.002100176876410842, 0.0029092696495354176, 0.002990093780681491, 0.003347473917528987, 0.0034870256204158068, 0.0054482086561620235, 0.006403734441846609])\n",
      "Neighbors of column 272: ([272, 189, 236, 38, 376, 466, 106, 44, 196, 305], [0.0, 0.012700006365776062, 0.013006048277020454, 0.013151892460882664, 0.013188105076551437, 0.013192594051361084, 0.013255701400339603, 0.013527178205549717, 0.013858034275472164, 0.014155939221382141])\n",
      "Neighbors of column 285: ([285, 106, 466, 189, 236, 38, 376, 305, 44, 41], [0.0, 0.01580706425011158, 0.015833431854844093, 0.016042903065681458, 0.016297215595841408, 0.016315504908561707, 0.016384778544306755, 0.016515223309397697, 0.016558408737182617, 0.016804978251457214])\n",
      "Neighbors of column 287: ([287, 106, 236, 189, 44, 376, 466, 305, 38, 41], [0.0, 0.005326504819095135, 0.0054482086561620235, 0.005459148436784744, 0.005609896965324879, 0.005889808293431997, 0.006281562149524689, 0.006659263279289007, 0.007217638660222292, 0.008170482702553272])\n",
      "Neighbors of column 293: ([293, 189, 106, 466, 38, 236, 44, 305, 376, 196], [0.0, 0.02444329671561718, 0.024606073275208473, 0.02461817115545273, 0.024630317464470863, 0.02473895438015461, 0.02489500120282173, 0.02489989437162876, 0.024952497333288193, 0.025033527985215187])\n",
      "Neighbors of column 301: ([301, 466, 189, 376, 236, 38, 44, 106, 305, 287], [0.0, 0.016726719215512276, 0.017079394310712814, 0.017232252284884453, 0.01731848530471325, 0.0174863301217556, 0.01750330440700054, 0.017533963546156883, 0.017628923058509827, 0.017927272245287895])\n",
      "Neighbors of column 305: ([305, 106, 466, 189, 236, 38, 44, 376, 287, 196], [0.0, 0.0018269802676513791, 0.0025837391149252653, 0.0025837465655058622, 0.0034870256204158068, 0.004256741143763065, 0.004284639377146959, 0.004683435894548893, 0.006659263279289007, 0.007101088762283325])\n",
      "Neighbors of column 321: ([321, 106, 466, 189, 38, 376, 236, 44, 305, 41], [0.0, 0.023261260241270065, 0.02328174002468586, 0.023299720138311386, 0.023523734882473946, 0.023619836196303368, 0.02362232655286789, 0.023705383762717247, 0.02407473511993885, 0.0242866612970829])\n",
      "Neighbors of column 323: ([323, 189, 466, 44, 38, 106, 236, 376, 305, 196], [0.0, 0.009929041378200054, 0.010148695670068264, 0.010363704524934292, 0.01056311558932066, 0.010580016300082207, 0.010912807658314705, 0.011388559825718403, 0.011466797441244125, 0.011835112236440182])\n",
      "Neighbors of column 337: ([337, 106, 466, 38, 189, 44, 305, 236, 376, 41], [0.0, 0.024077214300632477, 0.024104420095682144, 0.024119297042489052, 0.02424502559006214, 0.024433480575680733, 0.024475019425153732, 0.024479851126670837, 0.024574659764766693, 0.024603692814707756])\n",
      "Neighbors of column 342: ([342, 189, 466, 376, 44, 236, 106, 38, 41, 305], [0.0, 0.020223915576934814, 0.020399926230311394, 0.0204116553068161, 0.020597614347934723, 0.020641028881072998, 0.02069869078695774, 0.02079639583826065, 0.020890727639198303, 0.02107541449368])\n",
      "Neighbors of column 346: ([346, 38, 466, 376, 236, 189, 106, 44, 305, 196], [0.0, 0.02304512821137905, 0.02328438125550747, 0.023292113095521927, 0.023304874077439308, 0.023368770256638527, 0.02343493513762951, 0.023574357852339745, 0.02362244576215744, 0.023657692596316338])\n",
      "Neighbors of column 347: ([347, 38, 189, 466, 236, 44, 106, 376, 305, 287], [0.0, 0.017128152772784233, 0.017218410968780518, 0.017232203856110573, 0.0172736756503582, 0.01743505522608757, 0.017486294731497765, 0.017703138291835785, 0.017870690673589706, 0.01813879981637001])\n",
      "Neighbors of column 366: ([366, 466, 38, 189, 44, 305, 236, 106, 376, 287], [0.0, 0.028168292716145515, 0.02836655080318451, 0.028400180861353874, 0.028444090858101845, 0.028471436351537704, 0.028500687330961227, 0.028557082638144493, 0.02863425947725773, 0.02875882014632225])\n",
      "Neighbors of column 374: ([374, 466, 189, 38, 44, 236, 376, 106, 305, 287], [0.0, 0.008903571404516697, 0.00905626080930233, 0.009512071497738361, 0.009574494324624538, 0.009617998264729977, 0.009874863550066948, 0.0099709527567029, 0.010455364361405373, 0.01071436982601881])\n",
      "Neighbors of column 375: ([375, 236, 189, 376, 106, 38, 44, 466, 305, 287], [0.0, 0.01084707397967577, 0.011118450202047825, 0.011145215481519699, 0.011283385567367077, 0.011487571522593498, 0.011559942737221718, 0.01155996322631836, 0.012044810689985752, 0.01232845801860094])\n",
      "Neighbors of column 376: ([466, 376, 236, 189, 44, 106, 38, 305, 41, 287], [0.0, 0.0, 0.002100176876410842, 0.0031074085272848606, 0.0031265169382095337, 0.003996752202510834, 0.00451495498418808, 0.004683435894548893, 0.005787723697721958, 0.005889808293431997])\n",
      "Neighbors of column 380: ([380, 189, 466, 38, 376, 106, 236, 44, 287, 41], [0.0, 0.00788844097405672, 0.008393603377044201, 0.008393618278205395, 0.008414898999035358, 0.008569297380745411, 0.008638577535748482, 0.009238691069185734, 0.00974117312580347, 0.009759511798620224])\n",
      "Neighbors of column 402: ([402, 376, 38, 466, 106, 236, 305, 189, 44, 287], [0.0, 0.009442891925573349, 0.01006022933870554, 0.010160432197153568, 0.010253867134451866, 0.010443935170769691, 0.010500866919755936, 0.010686542838811874, 0.010708780959248543, 0.010753235779702663])\n",
      "Neighbors of column 404: ([404, 189, 466, 376, 44, 236, 106, 38, 305, 287], [0.0, 0.023536430671811104, 0.023594537749886513, 0.023645060136914253, 0.023740561679005623, 0.023848338052630424, 0.023855824023485184, 0.023915745317935944, 0.02416863664984703, 0.02429402805864811])\n",
      "Neighbors of column 412: ([412, 38, 189, 466, 44, 106, 376, 305, 236, 287], [0.0, 0.01029451284557581, 0.010466781444847584, 0.010613778606057167, 0.010675355792045593, 0.010858065448701382, 0.011086245067417622, 0.011102364398539066, 0.011198566295206547, 0.011784662492573261])\n",
      "Neighbors of column 414: ([414, 106, 44, 376, 236, 189, 466, 38, 305, 287], [0.0, 0.007804834749549627, 0.007858093827962875, 0.007888407446444035, 0.007956109009683132, 0.0079561248421669, 0.008597039617598057, 0.008693576790392399, 0.009003442712128162, 0.009270875714719296])\n",
      "Neighbors of column 425: ([425, 466, 44, 189, 236, 106, 38, 376, 305, 287], [0.0, 0.014290010556578636, 0.014410438947379589, 0.014636226929724216, 0.014798198826611042, 0.014946477487683296, 0.01511700265109539, 0.015223096124827862, 0.01579195074737072, 0.016242191195487976])\n",
      "Neighbors of column 431: ([431, 189, 38, 466, 44, 106, 236, 376, 305, 196], [0.0, 0.008727822452783585, 0.008890205062925816, 0.009283749386668205, 0.009411263279616833, 0.0094112828373909, 0.009667466394603252, 0.009850707836449146, 0.010178063996136189, 0.01068096049129963])\n",
      "Neighbors of column 441: ([441, 236, 44, 189, 466, 106, 376, 305, 196, 287], [0.0, 0.029158184304833412, 0.02921936847269535, 0.029231736436486244, 0.029249999672174454, 0.02939433790743351, 0.029455162584781647, 0.029471350833773613, 0.02950766682624817, 0.029533913359045982])\n",
      "Neighbors of column 443: ([443, 466, 38, 189, 376, 106, 236, 44, 305, 196], [0.0, 0.025185473263263702, 0.02521626651287079, 0.025254083797335625, 0.025343598797917366, 0.02541869878768921, 0.025442151352763176, 0.02549591101706028, 0.025559058412909508, 0.02584194205701351])\n",
      "Neighbors of column 446: ([446, 236, 44, 106, 466, 189, 38, 376, 305, 41], [0.0, 0.01675165258347988, 0.01690744049847126, 0.017023414373397827, 0.01703740656375885, 0.0170724056661129, 0.017197612673044205, 0.017639053985476494, 0.017713239416480064, 0.01821422390639782])\n",
      "Neighbors of column 451: ([451, 189, 106, 236, 38, 466, 376, 44, 305, 196], [0.0, 0.02720608562231064, 0.027216972783207893, 0.02732626534998417, 0.027337193489074707, 0.027343684807419777, 0.027511080726981163, 0.02755643241107464, 0.02775053307414055, 0.027945242822170258])\n",
      "Neighbors of column 466: ([106, 189, 376, 466, 236, 305, 38, 44, 196, 41], [0.0, 0.0, 0.0, 0.0, 0.0017605188768357038, 0.0025837391149252653, 0.0032018693163990974, 0.003782191313803196, 0.005480926483869553, 0.005889794789254665])\n",
      "Neighbors of column 469: ([469, 189, 466, 376, 106, 44, 236, 38, 305, 196], [0.0, 0.015712464228272438, 0.015735162422060966, 0.01579946279525757, 0.015878459438681602, 0.016079850494861603, 0.01612061634659767, 0.0162934809923172, 0.01668032445013523, 0.017005855217576027])\n",
      "Neighbors of column 470: ([470, 236, 466, 106, 44, 376, 189, 38, 305, 41], [0.0, 0.0288705937564373, 0.02902294136583805, 0.02911522425711155, 0.029160164296627045, 0.029219498857855797, 0.029233790934085846, 0.029237836599349976, 0.029612598940730095, 0.02976110391318798])\n",
      "Neighbors of column 473: ([473, 236, 38, 189, 106, 466, 44, 376, 305, 287], [0.0, 0.01693566143512726, 0.017339129000902176, 0.017359759658575058, 0.017417989671230316, 0.01759163849055767, 0.017699699848890305, 0.017703138291835785, 0.01773005537688732, 0.017960479483008385])\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "\n",
    "# Example data: 10000 samples, 128 features (columns)\n",
    "# n_samples, n_features = 10000, 128\n",
    "# np.random.seed(1234)\n",
    "# data = np.random.random((n_samples, n_features)).astype('float32')\n",
    "\n",
    "data = correlated_matrix\n",
    "\n",
    "# Normalize columns to unit length for cosine similarity\n",
    "data_norm = data / np.linalg.norm(data, axis=0, keepdims=True)\n",
    "\n",
    "# Transpose to treat columns as vectors: shape (n_features, n_samples)\n",
    "vectors = data_norm.T\n",
    "\n",
    "d = vectors.shape[1]\n",
    "\n",
    "# Build Annoy index with angular (cosine) distance\n",
    "index = AnnoyIndex(d, 'angular')\n",
    "\n",
    "# Add each column vector to index\n",
    "for i in range(n_features):\n",
    "    index.add_item(i, vectors[i])\n",
    "\n",
    "# Build trees for indexing (higher number means more accuracy, higher build time)\n",
    "index.build(10)\n",
    "\n",
    "# Query first 3 columns: nearest neighbors by number (k)\n",
    "k = 10\n",
    "for i in range(n_features):\n",
    "    neighbors = index.get_nns_by_item(i, 2, include_distances=True)\n",
    "    # print(f\"Neighbors of column {i}: {neighbors}\")\n",
    "    if neighbors[1][1] < 0.03 :\n",
    "        neighbors = index.get_nns_by_item(i, k, include_distances=True)\n",
    "        print(f\"Neighbors of column {i}: {neighbors}\")\n",
    "print(f\"Finished\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935521e-9274-4eb4-a3c7-bb469c6d86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-gpu-cu12  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d248c-5cac-4368-96fe-db93e883af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "n_features = 500\n",
    "\n",
    "base_col = torch.randn(n_samples, 1)  # base column vector\n",
    "\n",
    "# Define a noise vector with a different noise scale per column\n",
    "noise_scales = torch.rand(n_features) * 0.3  # e.g., noise std dev between 0 and 0.1\n",
    "\n",
    "# Generate noise matrix with shape (n_samples, n_features)\n",
    "noise = torch.randn(n_samples, n_features) * noise_scales  # automatically broadcasts noise_scales along rows\n",
    "\n",
    "# Add different noise to each column based on noise_scales\n",
    "correlated_matrix = base_col + noise\n",
    "\n",
    "print(correlated_matrix.shape)  # (10000, 500)\n",
    "\n",
    "# Check correlation for a few columns\n",
    "corr_matrix = torch.corrcoef(correlated_matrix.T)\n",
    "print(corr_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d74b76-5501-40c9-9774-21548f19ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    df = df.select_dtypes(include=['number']).astype(float)\n",
    "    \n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    filtered = ~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    df_clean = df[filtered]\n",
    "    return df_clean\n",
    "\n",
    "df_x = remove_outliers(X_sampled)\n",
    "df_y = y_sampled.loc[df_x.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9026409-eb9b-49a0-8333-56b39acbb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create an example tensor of arbitrary shape, e.g., (batch, channels, height, width)\n",
    "tensor = torch.randn(4, 3, 5, 6)\n",
    "\n",
    "# To extract and convert the last two dimensions (height and width for example),\n",
    "# keep all dimensions except the last two and then convert to numpy\n",
    "last_two_dims_numpy = tensor[..., :, :].reshape(-1, tensor.size(-2), tensor.size(-1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1d61d9-cc57-4174-b69c-bc81fbf54bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_two_dims_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e160221-ae1a-457a-b28d-485bb624190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1: tensor([[[[-0.1418,  0.7054,  1.0820, -0.1088],\n",
      "          [ 0.8939, -0.2707,  0.1073,  0.4607]]]])\n",
      "tensor2: tensor([[[[ 0.1233, -0.8613,  2.4167, -0.1384],\n",
      "          [ 0.3667,  3.0996, -1.3968, -0.2889]]]])\n",
      "[[ 2.0048697   0.65455794]\n",
      " [ 0.5388876  -0.79417306]]\n",
      "[[0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "d = 4\n",
    "v_dim = 5\n",
    "\n",
    "tensor1 = torch.randn(1, 1, 2, d)\n",
    "tensor2 = torch.randn(1, 1, 2, d)\n",
    "tensorV = torch.randn(1, 1, 2, v_dim)\n",
    "print(f\"tensor1: {tensor1}\")\n",
    "print(f\"tensor2: {tensor2}\")\n",
    "\n",
    "vector1 = tensor1[0,0,:,:]\n",
    "vector2 = tensor2[0,0,:,:]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "# index.add(vector1)\n",
    "index.add(vector2)\n",
    "\n",
    "distances, labels = index.search(vector1, k = 2)\n",
    "\n",
    "print(distances)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3976ec5-c16a-4bd0-ba77-6b8deea8a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vector1.shape)\n",
    "# sum_squares_1 = np.sum(vector1.numpy()**2)\n",
    "# print(sum_squares_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bec0343-a2b2-438a-ac3d-675a0348c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores:tensor([[[[0., 0.],\n",
      "          [0., 0.]]]]) \n",
      "query_idx: tensor([[0, 0],\n",
      "        [1, 1]]) indices: tensor([[0, 1],\n",
      "        [0, 1]]), shape dists: tensor([[ 2.0049,  0.6546],\n",
      "        [ 0.5389, -0.7942]])\n",
      "Shape query_idx: torch.Size([2, 2]) indices: torch.Size([2, 2]), shape dists: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.zeros(1, 1, 2, 2, dtype=torch.float32)\n",
    "print(f\"Attention scores:{attn_scores} \")   \n",
    "\n",
    "query_idx = torch.arange(2).unsqueeze(1).expand(2, 2) \n",
    "\n",
    "indices = torch.tensor(labels) \n",
    "dists = torch.tensor(distances, dtype=torch.float32)\n",
    "\n",
    "print(f\"query_idx: {query_idx} indices: {indices}, shape dists: {dists}\")\n",
    "print(f\"Shape query_idx: {query_idx.shape} indices: {indices.shape}, shape dists: {dists.shape}\")\n",
    "\n",
    "attn_scores[0, 0, query_idx, indices]  = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b3b113a-9f37-4a8e-9c83-d14bda0c88f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.0049,  0.6546],\n",
       "          [ 0.5389, -0.7942]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1aa954d-57a7-469c-a737-a1170a39cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.4596,  1.7555, -0.5378, -1.4331,  2.4042],\n",
       "          [ 0.2010, -1.5601,  1.3265,  0.4212,  0.0976]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(attn_scores, tensorV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022bd33-8e08-4946-8279-94e89bca3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_head_outputs_scaled = torch.nn.functional.scaled_dot_product_attention(\n",
    "                    tensor1,\n",
    "                    tensor2,\n",
    "                    tensorV\n",
    "                )\n",
    "attention_head_outputs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308b85b5-df31-4262-a404-529397eb8fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from memory_profiler) (5.9.0)\n",
      "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: memory_profiler\n",
      "Successfully installed memory_profiler-0.61.0\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf97e4b-e0c7-42f8-a7f1-a0ed7d30c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/graph_temporal/lib/python3.12/inspect.py:497: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(object, types.FrameType)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                         int |     2096080 |     59.73 MB\n",
      "                         str |      391375 |     57.35 MB\n",
      "                        code |       91389 |     38.46 MB\n",
      "                        list |       42345 |     29.47 MB\n",
      "                        dict |      105440 |     29.13 MB\n",
      "                        type |       11737 |     14.78 MB\n",
      "                       tuple |      152257 |      9.08 MB\n",
      "     collections.OrderedDict |        7437 |      3.90 MB\n",
      "                         set |        5119 |      2.88 MB\n",
      "           inspect.Parameter |       36592 |      2.23 MB\n",
      "        asttokens.util.Token |       18200 |      2.08 MB\n",
      "                 abc.ABCMeta |        1104 |      1.74 MB\n",
      "                        cell |       40670 |      1.55 MB\n",
      "       weakref.ReferenceType |       18888 |      1.44 MB\n",
      "  builtin_function_or_method |       18262 |      1.25 MB\n"
     ]
    }
   ],
   "source": [
    "from pympler import muppy, summary\n",
    "\n",
    "# Create some objects\n",
    "my_list = [1] * (10**6)\n",
    "\n",
    "# Get all existing Python objects\n",
    "all_objects = muppy.get_objects()\n",
    "\n",
    "# Summarize memory used by types of objects\n",
    "sum1 = summary.summarize(all_objects)\n",
    "summary.print_(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc607e51-4817-4d31-a3a7-b6fe85828883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/sg/nff54zj50zl8mzy2j3lnw34w0000gn/T/ipykernel_81385/1718517272.py\", line 11, in <module>\n",
      "    traceback.print_stack()\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "try:\n",
    "    # some code that can raise an exception\n",
    "    1 / 0\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\")\n",
    "    # exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "    # print(\"Printing stack trace using traceback.print_tb:\")\n",
    "    # traceback.print_tb(exc_traceback, limit=None, file=sys.stdout)\n",
    "    traceback.print_stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4363a-b37d-4a2f-87ef-99f0058329ce",
   "metadata": {},
   "source": [
    "# Gathering indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f384fd7-ae0d-4b08-aa01-8ea80eb68e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e71a252d-e613-4b8b-8a5a-ae50dd55c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked_attn_scores: torch.Size([6, 10, 3])\n",
      "attn_scores_indices.shape: torch.Size([2, 3, 10, 3])\n",
      "expanded: tensor([[[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "         [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "         [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]],\n",
      "\n",
      "        [[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "         [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "         [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]],\n",
      "\n",
      "        [[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "         [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "         [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]],\n",
      "\n",
      "        [[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "         [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19],\n",
      "         [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]],\n",
      "\n",
      "        [[19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19],\n",
      "         [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
      "         [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]],\n",
      "\n",
      "        [[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "         [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
      "         [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]],\n",
      "\n",
      "        [[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
      "         [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "         [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]],\n",
      "\n",
      "        [[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
      "         [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
      "         [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]],\n",
      "\n",
      "        [[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
      "         [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
      "         [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]],\n",
      "\n",
      "        [[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "         [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
      "         [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]]])\n",
      "shape of indices_expanded: torch.Size([2, 3, 10, 3, 15])\n",
      "shape of v_contiguous: torch.Size([2, 3, 10, 15])\n",
      "shape of v_contiguous_expanded: torch.Size([2, 3, 10, 15, 15])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 16 is out of bounds for dimension 3 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape of v_contiguous_expanded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_contiguous_expanded.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# shape => (B, H, seq_len_q, n_neighbours, k_dim)\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Gather values from V along seq_len dimension (dim=2)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m neighbor_values = torch.gather(v_contiguous_expanded, dim=\u001b[32m3\u001b[39m, index=indices_expanded)\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape of neighbor_values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneighbor_values.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: index 16 is out of bounds for dimension 3 with size 15"
     ]
    }
   ],
   "source": [
    "batch = 2\n",
    "n_head = 3\n",
    "q_contiguous = torch.rand(batch, n_head, 10, 10, dtype=torch.float32)\n",
    "v_contiguous = torch.rand(batch, n_head, 10, 15, dtype=torch.float32)\n",
    "\n",
    "n_similar_faiss =3\n",
    "# attn_scores = torch.zeros(2, 3, 10, n_similar_faiss, dtype=torch.float32)\n",
    "# attn_scores_indices = torch.zeros(2, 3, 10, n_similar_faiss, dtype=torch.float32)\n",
    "attn_scores_list = []\n",
    "attn_scores_indices_list = []\n",
    "\n",
    "for b in range(q_contiguous.shape[0]):\n",
    "    for h in range(q_contiguous.shape[1]):\n",
    "        # query_idx = torch.arange(q_contiguous.shape[2]).unsqueeze(1).expand(q_contiguous.shape[2], n_similar_faiss)  # shape: (q_len, n_sim)\n",
    "        dists = torch.rand(q_contiguous.shape[2], 3, dtype=torch.float32)\n",
    "        indices = torch.randint(11, 20, (q_contiguous.shape[2], 3), dtype=torch.int64)\n",
    "        # print(f\"indices: {indices}\")\n",
    "        # print(f\"dists: {dists}\")\n",
    "        # print(f\"query_idx: {query_idx}\")\n",
    "        attn_scores_list.append(dists)\n",
    "        attn_scores_indices_list.append(indices)\n",
    "        \n",
    "stacked_attn_scores = torch.stack(attn_scores_list, dim=0) \n",
    "stacked_attn_scores_indices = torch.stack(attn_scores_indices_list, dim=0) \n",
    "\n",
    "print(f\"stacked_attn_scores: {stacked_attn_scores.shape}\")\n",
    "attn_scores = stacked_attn_scores.view(batch, n_head, stacked_attn_scores.shape[1], stacked_attn_scores.shape[2])\n",
    "attn_scores_indices = stacked_attn_scores_indices.view(batch, n_head, stacked_attn_scores_indices.shape[1], stacked_attn_scores_indices.shape[2])\n",
    "\n",
    "# print(attn_scores[0,0,:,:])\n",
    "# print(attn_scores_indices[0,0,:,:])\n",
    "\n",
    "print(f\"attn_scores_indices.shape: {attn_scores_indices.shape}\")\n",
    "# Gathering values from \n",
    "indices_expanded = attn_scores_indices\n",
    "indices_expanded = attn_scores_indices.unsqueeze(-1).expand(-1, -1, -1,-1, v_contiguous.size(-1))\n",
    "print(f\"expanded: {indices_expanded[0,0,:,:,:]}\")\n",
    "v_contiguous_expanded = v_contiguous.unsqueeze(-1).expand(-1, -1, -1,-1, v_contiguous.size(-1))\n",
    "print(f\"shape of indices_expanded: {indices_expanded.shape}\")\n",
    "print(f\"shape of v_contiguous: {v_contiguous.shape}\")\n",
    "print(f\"shape of v_contiguous_expanded: {v_contiguous_expanded.shape}\")\n",
    "# shape => (B, H, seq_len_q, n_neighbours, k_dim)\n",
    "\n",
    "# Gather values from V along seq_len dimension (dim=2)\n",
    "neighbor_values = torch.gather(v_contiguous_expanded, dim=3, index=indices_expanded)\n",
    "print(f\"shape of neighbor_values: {neighbor_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8285879e-d199-43cc-885f-c293b91fbe53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10, 15])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_heads = torch.einsum('bhti,bhtik->bhtk', attn_scores, neighbor_values)\n",
    "\n",
    "attention_heads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ce62244-1d9d-4561-afed-667299a752bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11986817 0.71472432 0.37543603]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "d = 3\n",
    "index = faiss.IndexFlatIP(d)\n",
    "\n",
    "arr = np.random.rand(5, 3)\n",
    "\n",
    "# Multiply rows by -1\n",
    "negated_arr = -arr\n",
    "\n",
    "# Concatenate original and negated arrays horizontally (side-by-side)\n",
    "# or vertically (stacked rows) depending on requirement\n",
    "\n",
    "# To concatenate rows (stack vertically) -> final shape (10, 3)\n",
    "vectors = np.vstack((arr, negated_arr))\n",
    "\n",
    "query = vectors[0:1,:]\n",
    "print(query)\n",
    "neg_query = -query\n",
    "query_vectors = np.vstack((query, neg_query))\n",
    "\n",
    "vectors = vectors[1:6,:]\n",
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ace96d3e-aae8-4c71-93c0-c450d465af23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43978268,  0.6987938 ,  0.19618884],\n",
       "       [ 0.38634747,  0.66174179,  0.24232956],\n",
       "       [ 0.72092435,  0.31196014,  0.64357024],\n",
       "       [ 0.37540066,  0.97741471,  0.33408207],\n",
       "       [-0.11986817, -0.71472432, -0.37543603]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "712a9922-4ffc-42b4-9ccb-27a4c1e4f504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11986817, 0.71472432, 0.37543603]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = vectors[0:1,:]\n",
    "# neg_query = -query\n",
    "# query_vectors = np.vstack((query, neg_query))\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2060b6ca-6635-42f2-be1a-8af5d6aaf7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4317d5e3-e77d-4aa7-8c2f-824ab79109de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: []\n",
      "distances: []\n"
     ]
    }
   ],
   "source": [
    "lims, distances, labels  = index.range_search(query, thresh = 0.9)\n",
    "print(f\"labels: {labels}\")\n",
    "print(f\"distances: {distances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09b92def-b60a-492b-9154-c54a95d6b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: []\n",
      "distances: []\n"
     ]
    }
   ],
   "source": [
    "lims, distances, labels  = index.range_search(neg_query, thresh = 0.9)\n",
    "print(f\"labels: {labels}\")\n",
    "print(f\"distances: {distances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0376ad9e-6f3d-4b96-8b7c-050c98c92ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels - arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67e5eea8-56ab-423a-953a-232c8ed5cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m index.range_search(x, thresh, *, params=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "    \u001b[38;5;28;01mdef\u001b[39;00m replacement_range_search(self, x, thresh, *, params=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
       "        \u001b[33m\"\"\"Search vectors that are within a distance of the query vectors.\u001b[39m\n",
       "\n",
       "\u001b[33m        Parameters\u001b[39m\n",
       "\u001b[33m        ----------\u001b[39m\n",
       "\u001b[33m        x : array_like\u001b[39m\n",
       "\u001b[33m            Query vectors, shape (n, d) where d is appropriate for the index.\u001b[39m\n",
       "\u001b[33m            `dtype` must be float32.\u001b[39m\n",
       "\u001b[33m        thresh : float\u001b[39m\n",
       "\u001b[33m            Threshold to select neighbors. All elements within this radius are returned,\u001b[39m\n",
       "\u001b[33m            except for maximum inner product indexes, where the elements above the\u001b[39m\n",
       "\u001b[33m            threshold are returned\u001b[39m\n",
       "\u001b[33m        params : SearchParameters\u001b[39m\n",
       "\u001b[33m            Search parameters of the current search (overrides the class-level params)\u001b[39m\n",
       "\n",
       "\n",
       "\u001b[33m        Returns\u001b[39m\n",
       "\u001b[33m        -------\u001b[39m\n",
       "\u001b[33m        lims: array_like\u001b[39m\n",
       "\u001b[33m            Starting index of the results for each query vector, size n+1.\u001b[39m\n",
       "\u001b[33m        D : array_like\u001b[39m\n",
       "\u001b[33m            Distances of the nearest neighbors, shape `lims[n]`. The distances for\u001b[39m\n",
       "\u001b[33m            query i are in `D[lims[i]:lims[i+1]]`.\u001b[39m\n",
       "\u001b[33m        I : array_like\u001b[39m\n",
       "\u001b[33m            Labels of nearest neighbors, shape `lims[n]`. The labels for query i\u001b[39m\n",
       "\u001b[33m            are in `I[lims[i]:lims[i+1]]`.\u001b[39m\n",
       "\n",
       "\u001b[33m        \"\"\"\u001b[39m\n",
       "        n, d = x.shape\n",
       "        \u001b[38;5;28;01massert\u001b[39;00m d == self.d\n",
       "        x = np.ascontiguousarray(x, dtype=\u001b[33m'float32'\u001b[39m)\n",
       "        thresh = float(thresh)\n",
       "\n",
       "        res = RangeSearchResult(n)\n",
       "        self.range_search_c(n, swig_ptr(x), thresh, res, params)\n",
       "        \u001b[38;5;66;03m# get pointers and copy them\u001b[39;00m\n",
       "        lims = rev_swig_ptr(res.lims, n + \u001b[32m1\u001b[39m).copy()\n",
       "        nd = int(lims[-\u001b[32m1\u001b[39m])\n",
       "        D = rev_swig_ptr(res.distances, nd).copy()\n",
       "        I = rev_swig_ptr(res.labels, nd).copy()\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m lims, D, I\n",
       "\u001b[31mFile:\u001b[39m      /opt/anaconda3/envs/graph_temporal/lib/python3.12/site-packages/faiss/class_wrappers.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??index.range_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "890976a7-00b1-4471-978d-3fff872d40a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8690071]], dtype=float32), array([[3]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1f3579a-fd7f-4a9b-99bb-a6ffc0d647a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.66615146]], dtype=float32), array([[4]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(neg_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c0374cf-0fd8-4876-8f27-333926e796ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_np(X, axis=0, p=2, eps=1e-12):\n",
    "    norm = np.linalg.norm(X, ord=p, axis=axis, keepdims=True)\n",
    "    norm = np.maximum(norm, eps)  # prevent division by zero\n",
    "    return X / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75dcfa73-18f5-4c31-9ccf-c889c56db933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized vector: [[0.01068057 0.94921714 0.31444038]\n",
      " [0.1550259  0.14712322 0.97689392]\n",
      " [0.43094687 0.76224373 0.4829796 ]\n",
      " [0.09517516 0.14854723 0.98431469]\n",
      " [0.24727722 0.87735555 0.41121919]]\n",
      "Dot product with itself: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a random vector\n",
    "v = np.random.rand(5,3)\n",
    "\n",
    "\n",
    "# Normalize the vector to unit length\n",
    "# v_normalized = v / norm\n",
    "v_normalized = normalize_np(v, axis=1)\n",
    "\n",
    "# Compute dot product of normalized vector with itself\n",
    "dot_product = np.dot(v_normalized[0,:], v_normalized[0,:])\n",
    "\n",
    "print(\"Normalized vector:\", v_normalized)\n",
    "print(\"Dot product with itself:\", dot_product) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "303e9b5f-3af7-4bfd-98db-d85aeade1db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "dp = 0\n",
    "for id, el in enumerate(v_normalized):\n",
    "    dp += el * el\n",
    "\n",
    "print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4df1a7-1a3f-4803-a0c8-dc6597418cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_np()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 graph_temporal",
   "language": "python",
   "name": "graph_temporal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
